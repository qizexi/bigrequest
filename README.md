高并发或者大批量数据解决探讨：
业务场景：
	我是在电商公司工作，双11当天的订单量有50万单左右，怎么样在一天内处理完50万个订单面临了一个问题，因为50万订单要经过很多的加工最后才能出库。一个订单的处理流程大体是这样的：读取各个电商平台的订单进入系统，然后对订单信息（如，收货信息，商品信息等）进行验证，然后保存到系统；接着系统要对订单进行分配仓库，分配物流，接着进行库存占用，接着才到仓库打单，更新发货。
	
	当时我们解决方案是，对数据表进行拆分，分出热点数据、近期数据和历史数据，还有程序那边也把某些使用频繁但是数据量又不大的直接放入内存，轻松的解决了上述问题。
	
	但是后面还发现我们可以做得更好，就是可以在利用数据库的批量操作原理，就是一条条的写入改为批量写入速度可以大大的提高。
	
	一条条数据写入(慢)：
	INSERT INTO test_reg(r_nick, r_name, r_sex, r_phone, r_addr, r_recflag) VALUES ('qizexi', 'abc', '1', '13607765481', '广东省广州市白云区', MD5('123456'))
	
	数据库批量写入(非常快)：
	INSERT INTO test_reg(r_nick, r_name, r_sex, r_phone, r_addr, r_recflag) VALUES ('qizexi', 'abc', '1', '13607765481', '广东省广州市白云区', MD5('123456')),('qizexi2', 'abc', '1', '13607765481', '广东省广州市白云区', MD5('123456')),('qizexi3', 'abc', '1', '13607765481', '广东省广州市白云区', MD5('123456')),......
	
	但是我们知道客户端是一个个发来请求的，怎么样既要快速的响应每一个客户端的请求，又可以达到批量处理的目的呢？
	这就要求服务器端要把这些请求存储起来先不处理等请求数量达到一定数量之后或者请求处理的定时器超时再把现有的请求处理，
	然后就可以做成批量写入或者更新数据库啦，这样既可以达到每一个客户端得到快速响应同时服务器端又可以快速处理数据。

程序实现：
	操作系统：win7 32位 
	硬件配置：intel i3 2代处理器 2g内存
	数据库：mysql innoDB
	程序语言：golang 1.53
	
	req_server.go
	该程序是客户端发起请求的时候先缓存起来等达到一定数量或者处理计时器超时的时候才会出来
	
	req_server2.go
	该程序是客户端发起请求就新开一个协程来立刻处理
	
	效率对比是req_server.go比req_server2.go速度的2-3倍，同时请求量的增多优势更加明显；
	还需要指出的是req_server.go程序没有写入不成功的，req_server2并发超过5000之后开始有出现写入数据库不成功的。

测试信息：
	对比1-1.jpg：是并发1500个请求的数据对比
	对比2-1.jpg：是并发6000个请求的数据对比
	bigdata.sql：是测试数据库文件
	
	
